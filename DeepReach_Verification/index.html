<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
    body {
        font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
        font-weight:300;
        font-size:18px;
        margin-left: auto;
        margin-right: auto;
        width: 1100px;
    }

    h1 {
        font-weight:300;
    }

    h2 {
        font-weight: 300;
    }

    .disclaimerbox {
        background-color: #eee;
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
        padding: 20px;
    }

    video.header-vid {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.header-img {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.rounded {
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    a:link,a:visited
    {
        color: #1367a7;
        text-decoration: none;
    }
    a:hover {
        color: #208799;
    }

    td.dl-link {
        height: 160px;
        text-align: center;
        font-size: 22px;
    }

    .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
                15px 15px 0 0px #fff, /* The fourth layer */
                15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
                20px 20px 0 0px #fff, /* The fifth layer */
                20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
                25px 25px 0 0px #fff, /* The fifth layer */
                25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
        margin-left: 10px;
        margin-right: 45px;
    }


    .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
        margin-top: 5px;
        margin-left: 10px;
        margin-right: 30px;
        margin-bottom: 5px;
    }

    .vert-cent {
        position: relative;
        top: 50%;
        transform: translateY(-50%);
    }

    hr
    {
        border: 0;
        height: 1.5px;
        background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
    }
</style>

<html>
  <head>
        <title>Formal Assurances for High-Dimensional Reachability</title>
        <meta property="og:title" content="Factored 3D" />
  </head>

  <body>
    <br>
    <center>
    <span style="font-size:42px">Generating Formal Safety Assurances for<br>High-Dimensional Reachability</span>
    </center>

    <br><br>
      <table align=center width=900px>
       <tr>
        <td align=center width=100px>
        <center>
        <span style="font-size:20px"><a href="https://www.linkedin.com/in/albertkuilin/">Albert Lin<sup>1</sup></a></span>
        </center>
        </td>

        <td align=center width=100px>
        <center>
        <span style="font-size:20px"><a href="http://people.eecs.berkeley.edu/~somil/">Somil Bansal<sup>2</sup></a></span>
        </center>
        </td>
     </tr>
    </table>

    <br>
    <table align=center width=700px>
       <tr>
        <td align=center width=100px>
        <center>
        <span style="font-size:15px"><sup>1</sup> Princeton University <sup>2</sup> University of Southern California</span>
        </center>
        </td>
     </tr>
    </table>
    <br><br>
   
    <!--
    <table align=center>
            <tr>
                <td width=1000>
                  <center>
                    <!- - METHOD VIDEO HERE - ->
                      <iframe width="840" height="473" src="#" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </center>
                </td>
            </tr>
    </table>
    -->
        

            <br>

            <br><br>
          <hr>
    <center><h1>Abstract</h1></center>

            <br>
            Providing formal safety and performance guarantees for autonomous systems is becoming increasingly important as they are integrated in our society. Hamilton-Jacobi (HJ) reachability analysis is a popular formal verification tool for providing these guarantees, since it can handle general nonlinear system dynamics, bounded adversarial system disturbances, and state and input constraints. 
However, it involves solving a PDE, whose computational and memory complexity scales exponentially with respect to the state dimensionality, making its direct use on large-scale systems intractable.
A recently proposed method called DeepReach overcomes this challenge by leveraging a sinusoidal neural network PDE solver for high-dimensional reachability problems, whose computational requirements scale with the complexity of the underlying reachable tube rather than the state space dimension.
Unfortunately, neural networks can make errors and thus the computed solution may not be safe, which falls short of achieving our overarching goal to provide formal safety assurances. 
In this work, we propose a method to compute an error bound for the DeepReach solution. 
This error bound can then be used for reachable tube correction, resulting in a provably safe approximation of the true reachable tube.
We also propose a scenario optimization-based approach to compute this error bound for general nonlinear dynamical systems.
We demonstrate the efficacy of the proposed approach in obtaining reachable tubes for high-dimensional rocket-landing and multi-vehicle collision-avoidance problems.
            <br><br>
          <hr>
         <!-- <table align=center width=550px> -->
            <table align=center width=650>
             <center><h1>Paper</h1></center>
                <tr>
                    <!--<td width=300px align=left>-->
                    <!-- <a href="http://arxiv.org/pdf/1603.08511.pdf"> -->
                  <!-- <td><a href="#"><img class="layered-paper-big" style="height:175px" src="./resources/images/paper.png"/></a></td> -->
                  <td><a href="./resources/DeepReach_Verification.pdf"><img style="height:280px" src="./resources/images/DeepReach_Verification_preview.png"/></a></td>
                  <td><span style="font-size:14pt">Lin, Bansal<br><br>
                          Generating Formal Safety Assurances for <br> High-Dimensional Reachability
                  <!-- [hosted on <a href="#">arXiv</a>]</a> -->
                    </td>
              </tr>
            </table>
          <br>

          <table align=center width=180px>
              <tr>
                  <td><span style="font-size:14pt"><center>
                      <a href="./resources/DeepReach_Verification.pdf">[pdf]</a>
                    </center></td>

                  <td><span style="font-size:14pt"><center>
                      <a href="./resources/bibtex.bib">[Bibtex]</a>
                    </center></td>
              </tr>
            </table>
              <br>

                <hr>

         <center><h1>Code</h1></center>
            <table align=center width=1000px>
                <tr>
                        <center>
                          <a href=''><img class="round" style="height:400" src="./resources/images/framework.png"/></a>
                        </center>
              </tr>
          </table>

            <table align=center width=800px>
              <tr><center> <br>
                <span style="font-size:28px">&nbsp;<a href='#'>[GitHub]</a>

                <span style="font-size:28px"></a></span>
              <br>
              </center></tr>
          </table>
            <br>
          <hr>

          <!-- 
          <center><h1>Results</h1></center>
          <table align=center width=900px>
              <tr>
                  <td width=600px>
                    <center>
                        <a href="./resources/images/results_simulation.png"><img src = "./resources/images/results_simulation.png" width="800px"></img></href></a><br>
                  </center>
                  </td>
              </tr>
                  <td width=600px>
                    <center>
                        <span style="font-size:14px"><i> <span style="font-weight:bold">Metrics</span> We evaluate LB-WayPtNav against a comparable end-to-end method and a purely geometric method which uses depth images to estimate an occupancy map of the environment for use in planning via Model Predictive Control (MPC). For the geometric method we compare against both an agent with memory which estimates an occupancy grid based on all the depth images thus far and one that is reactive and estimates an occupancy grid based only on its current view of the environment. All methods are tested on a set of 185 navigational goals in a previously unseen test environment. Our method is approximately 20-25% more successful on these new goals than the end-to-end method. The success rate of LB-WayPtNav, which itself is reactive, is comparable to that of the Mapping (memoryless) baseline. The remaining three metrics are computed on the subset of test goals on which all methods are successful. We find that the model based method navigates to the goal region 1.5 to 2 times as quickly as the end-to-end method with average acceleration approximately half that of the end-to-end method and average jerk approximately 1/20th that of the end-to-end method. LB-WayPtNav is comparable to the mapping based methods in terms of time to reach goal, acceleration, and jerk.</i>
                  </center>
                  </td>
              </tr>
          </table>
          <br>
          <table align=center width=900px>
              <tr>
                  <td width=600px>
                    <center>
                        <a href="./resources/images/velocity_profile.png"><img src = "./resources/images/velocity_profile.png" height="220px"></img></href></a><br>
                  </center>
                  </td>
              </tr>
                  <td width=600px>
                    <center>
                        <span style="font-size:14px"><i> <span style="font-weight:bold">Control Profiles</span> The proposed method produces significantly smoother control profiles than the end-to-end method which are much easier to track on a real physical system. The jerky profiles learned by the end-to-end method could lead to increased probability of hardware failure on a real system as well. Additionally, these jerky control profiles would lead to dramatically increased power usage and thus decreased battery life.</i>
                  </center>
                  </td>
              </tr>
          </table>
          <br>
          <table align=center width=900px>
              <tr>
                  <td width=600px>
                    <center>
                        <iframe width="560" height="315" src="https://www.youtube.com/embed/Eny_WAynRms" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>
                  </center>
                  </td>
              </tr>
                  <td width=600px>
                    <center>
                        <span style="font-size:14px"><i> <span style="font-weight:bold">Learned Visual Semantics</span> We find that, through the training process, the agent learns generalizable visual semantics of indoor<br> office environments (i.e. exiting a room by first locating the door and then moving through it, going around a chair that is only partially<br> visible, locating and moving into a hallway to then move into a room connected to this hallway). The agent exhibits this behavior <br>in visually diverse scenarios where providing such supervision explicitly can be very difficult.</i>
                  </center>
                  </td>
              </tr>
          </table>
          <hr>
         
          <center><h1>Hardware Experiments</h1></center>
          <!- - <center> - ->
            
            <br>
            <table align=center width=900px>
              <tr>
                  <td align=center>
                    <a href="./resources/images/front_fig_comp.png"><img src = "./resources/images/front_fig_comp.png" height=200px></img></href></a><br>
                  </td>
                  <td>
                    <p>We deploy our simulation trained algorithm on a Turtlebot 2 to test on real-world navigational scenarios. Each experiment is visualized from three different viewpoints, however the robot only sees the "First Person View" (also labeled Robot View). The other two viewpoints are provided for context only. We do not train or finetune our algorithm in any way on real data. All experiments are shown in realtime.</p>
                  </td>
              </tr>
            </table>
            <br>
            <br>
              <table align=center width=900px>
              <tr>
                  <td width=600px>
                    <center>
                        <a href="./resources/images/results_experiments.png"><img src = "./resources/images/results_experiments.png" width="800px"></img></href></a><br>
                  </center>
                  </td>
              </tr>
                  <td width=600px>
                    <center>
                        <span style="font-size:14px"><i> <span style="font-weight:bold">Metrics</span> In real-world experiments LB-WayPtNav continues to perform well, however performance of the mapping based methods degrades considerably due to errors in depth estimation on shiny/matte objects (bike frames, tires, computer monitors, etc.), on thin/intricate objects (power cables, chair legs), and in the presence of strong infared light (sunlight).</i>
                  </center>
                  </td>
              </tr>
          </table>
          <!- - </center> - ->
          <br> 

          <center><h2>Videos</h2></center>
          <table align=center>
            <tr>
              <td>
                <center>
                      <iframe width="373" height="210" src="#" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>
                </center>
              </td>

              <td>
                <center>
                      <iframe width="373" height="210" src="#" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>
                </center>
              </td>
            </tr>

            <tr>
              <td>
                <center>
                      <iframe width="373" height="210" src="#" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>
                </center>
              </td>

              <td>
                <center>
                      <iframe width="373" height="210" src="#" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>
                </center>
              </td>

            </tr>
          </table>

          <table align=center>
            <tr>
              <td>
                <center>
                      <iframe width="373" height="210" src="#" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>
                </center>
              </td>
            </tr>
            <td width=800px>
                <center>
                    <span style="font-size:14px"><i> <span style="font-weight:bold">---</span> ---</i>
                    <br><br><br>
                </center>
              </td>
          </table>

              <hr>
              <table align=center width=1000px>
              <tr>
                <td width=800px>
                  <center>
                    <h1>---</h1>
                  </center>
                </td>
              </tr>
              <tr>

                  <td width=800px>
                    <center>
                        <iframe width="560" height="315" src="https://www.youtube.com/embed/KO8hOEZT0XY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>
                  </center>
                  </td>
              </tr>
              <td width=600px>
                    <center>
                        <span style="font-size:14px"><i>---</i>
                        <br><br><br>
                  </center>
                  </td>
          </table>


           <hr>
           -->

            <table align=center width=1100px>
                <tr>
                    <td>
                      <left>
                <center><h1>Acknowledgements</h1></center>
                ---
                <br>
                <br>
                This webpage template was borrowed from some <a href="https://richzhang.github.io/colorization/">colorful folks</a>.
            </left>
        </td>
        </tr>
        </table>

        <br><br>
</body>
</html>
